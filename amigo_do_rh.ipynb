{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXW2gkd2uUsQcg2FL4S9mf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XxTeosxX/amigo-do-rh/blob/main/amigo_do_rh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esse projeto vamos ter que instalar dois pacotes externos ao colab  \n",
        "1 google-generativeai - para fazemos uso das apis de IA do google  \n",
        "2 pypdf - para poder ler arquivos pdf em forma de texto"
      ],
      "metadata": {
        "id": "gHw2rdgUtd4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OIa1P1VnZUJL"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pypdf import PdfReader\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "Hi4dNUCSZZ1o"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A chave da api foi inserida no colab como visto no final da aula 4  \n",
        "https://youtu.be/iwt4bOIHy7s?t=4682"
      ],
      "metadata": {
        "id": "6qGfwnNvt06f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "QLrCQOiKZhsZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "OSQ3ZQ4OZ8td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos fazer o download do pdf da clt do site da camara.  \n",
        "Fonte do pdf da clt https://bd.camara.leg.br/bd/handle/bdcamara/37179"
      ],
      "metadata": {
        "id": "cQR5bvjkb_lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bd.camara.leg.br/bd/bitstream/handle/bdcamara/37179/consolidacao_leis_trabalho_4ed.pdf"
      ],
      "metadata": {
        "id": "xwfSa_9YhBWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ler o pdf e colocar o texto dentro de um dataframe do pandas  "
      ],
      "metadata": {
        "id": "PoW9W66Zulxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "leitor = PdfReader(\"consolidacao_leis_trabalho_4ed.pdf\")\n",
        "numero_de_paginas = len(leitor.pages)\n",
        "\n",
        "#comecando da pagina dois pois a página 0 é capa e página 1 é contra capa e a página 2 é outra capa interna\n",
        "inicio = 3\n",
        "# finalizando na ultima página com alguma informação pois a ultima pagina é capa\n",
        "fim = numero_de_paginas -1\n",
        "\n",
        "paginas = []\n",
        "for numero_da_pagina in range(inicio, fim):\n",
        "  paginas.append({\n",
        "      'pagina': numero_da_pagina,\n",
        "      'texto': leitor.pages[numero_da_pagina].extract_text()\n",
        "  })"
      ],
      "metadata": {
        "id": "UCj_FXAiaf3J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(paginas)\n",
        "df.columns = [\"pagina\", \"texto\"]"
      ],
      "metadata": {
        "id": "OgPwbWYcdNzl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feito isso vamos agora gerar os embedding para os textos."
      ],
      "metadata": {
        "id": "rA9NXuuTuvht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_fn(text, model):\n",
        "  return genai.embed_content(model=model, content=text, task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]"
      ],
      "metadata": {
        "id": "TLm6ZK8BdX0l"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"models/embedding-001\""
      ],
      "metadata": {
        "id": "kr9_z2O7ipLF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Embeddings\"] = df.apply(lambda row: embed_fn(row[\"texto\"], model), axis=1)"
      ],
      "metadata": {
        "id": "FxDPnrfYdZI_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora aqui esta sendo feita a função para gerar a consulta e um teste para saber se a consulta funcionando como deveria."
      ],
      "metadata": {
        "id": "KyihGqSmu5PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_e_buscar_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model,\n",
        "                                 content=consulta,\n",
        "                                 task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "\n",
        "  produtos_escalares = np.dot(np.stack(df[\"Embeddings\"]), embedding_da_consulta)\n",
        "\n",
        "  # indice = np.argmax(produtos_escalares)\n",
        "  indices_dos_3_maiores = np.argpartition(produtos_escalares, -3)[-3:]\n",
        "  return [df.iloc[indice][\"texto\"] for indice in indices_dos_3_maiores]"
      ],
      "metadata": {
        "id": "qn3VlIezeZes"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consulta = \"Quantas vezes no ano eu posso tirar férias? Eu posso dividir os periodos?\"\n",
        "trecho = gerar_e_buscar_consulta(consulta, df, model)"
      ],
      "metadata": {
        "id": "CyBXJA1Oj53w"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações do modelo e criação do modelo de conversa."
      ],
      "metadata": {
        "id": "fW0yF5Y1vIBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"candidate_count\": 1\n",
        "}"
      ],
      "metadata": {
        "id": "rX-t4QHhzlvF"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = genai.GenerativeModel(\"gemini-1.0-pro\", generation_config=generation_config)"
      ],
      "metadata": {
        "id": "BXtRx25ZnZMK"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma função para formatar o tamanho da resposta"
      ],
      "metadata": {
        "id": "xYJzzbxEvSGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_com_quebra_de_linha(texto_longo):\n",
        "  largura_linha = 120\n",
        "  linhas_quebradas = textwrap.wrap(texto_longo, largura_linha)\n",
        "\n",
        "  for linha in linhas_quebradas:\n",
        "    print(linha)\n",
        "  print()\n",
        ""
      ],
      "metadata": {
        "id": "K8DWoJN8rI-n"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função que é o amigo do rh.\n",
        "Aqui vai fazer uso dos dois modelos (embedding e conversa) e vai ficar aguardando uma entrada de pergunta no chat."
      ],
      "metadata": {
        "id": "k63mlQ-evXfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_inicial = \"\"\"Você é um experiente profissional que trabalha em uma empresa e responde dúvidas dos funcionários e gerencia de uma forma mais simples,\n",
        "usando como base o seguinte texto da CLT:\n",
        "'{trechos}'.\n",
        "\n",
        "Responda à seguinte pergunta de um funcionário: '{consulta}'\"\"\""
      ],
      "metadata": {
        "id": "kiaEQuE_0Byn"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def amigo_do_rh(embedding_model, chat_model):\n",
        "  print('Este é o seu amigo do rh ele vai ler a CLT e responder perguntas de forma fácil de entender.')\n",
        "  print('Faça perguntas do tipo : ')\n",
        "  print('Posso prorrogar a experiência do meu funcionário mais de duas vezes?')\n",
        "  print('Qual é o periodo de experiência?')\n",
        "  print('Obs: Para encerrar a conversa com o amigo do rh. Digite fim e enter\\n')\n",
        "\n",
        "  chat = chat_model.start_chat(history=[])\n",
        "\n",
        "  while True:\n",
        "    consulta = input('>>> Esperando pergunda:\\n')\n",
        "    if consulta == 'fim':\n",
        "      break\n",
        "    trechos = gerar_e_buscar_consulta(consulta, df, embedding_model)\n",
        "    prompt = prompt_inicial.format(trechos=trechos, consulta=consulta)\n",
        "    response = chat.send_message(prompt)\n",
        "    print_com_quebra_de_linha(response.text)"
      ],
      "metadata": {
        "id": "XYrfyKkcZkxB"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amigo_do_rh(model, model_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "t9vJPbS1aYTa",
        "outputId": "9f1910aa-4957-4a0e-9762-31e1f80707e2"
      },
      "execution_count": 113,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Este é o seu amigo do rh ele vai ler a CLT e responder perguntas de forma fácil de entender.\n",
            "Faça perguntas do tipo : \n",
            "Posso prorrogar a experiência do meu funcionário mais de duas vezes?\n",
            "Qual é o periodo de experiência?\n",
            "Obs: Para encerrar a conversa com o amigo do rh. Digite fim e enter\n",
            "\n",
            ">>> Esperando pergunda:\n",
            "Posso prorrogar a experiência do meu funcionário mais de duas vezes?\n",
            "Não, o texto da CLT não permite a prorrogação da experiência por mais de duas vezes.\n",
            "\n",
            ">>> Esperando pergunda:\n",
            "fim\n"
          ]
        }
      ]
    }
  ]
}
